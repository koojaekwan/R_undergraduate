chapter 4.
================
Jae Kwan Koo

-   [고정점 반복](#고정점-반복)
    -   [Example)](#example)
-   [뉴턴알고리즘](#뉴턴알고리즘)
    -   [Example)](#example-1)
-   [가우스 뉴턴 알고리즘 (ppt 참조)](#가우스-뉴턴-알고리즘-ppt-참조)
-   [뉴턴 랩슨 알고리즘](#뉴턴-랩슨-알고리즘)
    -   [Example)](#example-2)
        -   [while문을 활용한 algorithm 몇 가지 추가.](#while문을-활용한-algorithm-몇-가지-추가.)

고정점 반복
-----------

비선형방정식의 해를 구하는 문제이다. 방정식을 최대, 최소로 만들어주는 모수의 참값을 알고싶은 것.
계산하는 알고리즘을 통해 반복적으로 해를 찾아 갈 것. 미지의 모수를 근사치로 찾아보자.

n번째의 값을 함수 g를 통해 변환하는 수를 생성.
순환공식은 직전의 값으로 부터 항상 계산되므로 초기치 세팅이 필요.

차이가 거의 없다면 `수렴` 이라고 한다. 그래서 허용한계치 입실론을 설정.
입실론보다 작으면 거의 차이가 안난다고 보고 수렴이라고 본다.

허용한계치보다 차이가 작아질때까지 반복해서 나간다.

둘의 차이가 입실론보다 작으면 되므로 분자만 쓰기도 하기도 하고, xn으로 나누어주기도 한다. 어느 것이 옳은지에 대한 여부는 없다.
두가지 차이는 xn을 나누어 주는 기준은 xn으로부터 변동이 크게 변화하는지 작게 변화했는지 확인하고 싶은 것이다. 값이 크게 나타나게 된다면 변동이 크고, 값이 작으면 변동이 작다.
변동이 작다는 것은 결국 수렴한 것이라고 보는 것이고, 변동이 크다는 것은 아직 수렴하지 않았음을 암시한다.

하지만, 결국 나누어서 보나 나누지 않고 보나 결과는 같을 것이다.
xn으로 나누어주면 값이 더 작아지게 될 것이므로, 수렴의 속도를 더 빠르게 해주기 위해서라고 생각할 수 있다.
허용한계치보다 작다면 반복을 중단하고 마지막값을 해로 추정.

더 빠르게 수렴을 하는데 문제가 되는 것의 예로 만약, 차이가 1만큼 나는데 (매우 큰 값이면 1차이는 별 차이가 없다.) 0에 가까운 작은 값으면 1은 굉장히 큰 값으로 생각된다.
모수의 참값을 정확하게 근사치로 찾아주기가 어렵다는 단점이 있다. (수렴의 속도가 빠르기는 하지만 이런 단점이 존재)

xn을 나누지 않으면, 위보다는 잘 찾을 수 있지만 계산량이 늘어난다. 즉, 수렴의 속도가 느리다.
허용한계치는 10^-6보다는 작은 값으로 두어 정확한 값을 찾고자 하는 알고리즘이라고 볼 수 있다.

기울기(g prime)가 0에 가까울수록 수렴속도가 빠르다. 기울기가 0이면 해를 찾는 의미가 없다.
상수함수에서 해를 구하려고 하지 않아도 눈으로 보기만해도 해를 볼 수 있다. 그래서 가장 빨리 찾을 수 있지만, 찾는 의미가 없다.

### Example)

*f*(*x*)=*x*<sup>2</sup> − *x* − 2 = 0, *x* &gt; 0 의 해를 구해보자.

-   g(x)=x^2-2
    *x* = *x*<sup>2</sup> − 2이므로, *g*(*x*)=*x*<sup>2</sup> − 2로 놓으면 *x* = *g*(*x*)를 만족한다. 그러나 $g^\`(x)$에서 x가 상한은 없지만 하한은 0보다 크므로 x는 무한대가 되면, 기울기가 무한대가 나올 수 있다. 무한대가 나오게 되면 상당히 애매해진다. 그러므로 *g*(*x*)=*x*<sup>2</sup> − 2는 순환함수로 사용할 수 없다.

-   g(x)=sqrt(x+2)

*x*<sup>2</sup> = *x* + 2이므로, $g(x)=\\sqrt{x+2}$로 놓으면, *x* = *g*(*x*)를 만족하고 x&gt;0에서 $g^\`(x)=1/2\\sqrt{x+2} \\le 1/\\sqrt{8}$이므로 조건을 만족한다. 그러므로 g(x)을 순환함수로 사용할 수 있다.
기울기는 $1/2\\sqrt{x+2}$, x는 0보다 크다. 0일때를 생각해보자. x값이 무한대가 된다면 값은 0이 될 것이다. 단순히 x가 0이라고 생각해보자. $1/\\sqrt{8}$이 될 것이다. x가 0에 가까워지니 이와같이 가까워 진다. 그래서 0과 1/root(8) 사이로 기울기의 값은 정해진다. 즉, 상한이 정해져 있다는 말.

x는 함수의 정의역에 의해 여기서 2보다 커야한다.
g(x)를 순환함수로 지정하고 초깃값을 0으로 선택한 후, 알고리즘에 따라 방정식의 해를 구해보자.

``` r
# recursive 

x1 <- 0      #초기치
n <- 1       #현재 반복횟수

while(T){
  x0 <- x1
  x1 <- sqrt(x0+2)
  change <- abs((x1-x0)/x0)
  cat(n, x1, change, '\n')
  
  if( change < 1e-6 ) break;
  n <- n+1
}
```

    ## 1 1.414214 Inf 
    ## 2 1.847759 0.306563 
    ## 3 1.961571 0.06159434 
    ## 4 1.990369 0.01468155 
    ## 5 1.997591 0.0036282 
    ## 6 1.999398 0.0009044519 
    ## 7 1.999849 0.0002259512 
    ## 8 1.999962 5.64777e-05 
    ## 9 1.999991 1.411879e-05 
    ## 10 1.999998 3.529659e-06 
    ## 11 1.999999 8.824122e-07

해 참값이 2이다라고 말은 어렵고 해 참값의 추정값은 2라고 하는게 맞을 듯하다.
프로그램은 문제가 없지만, 여기서 g라는 함수를 어떻게 찾아낼지가 항상 문제가 될 것이다.
*g*(*x*)를 어느 것을 사용하더라도 해를 찾기는 하지만, 정의역을 만족하는 해를 찾는가에 따라 다르다.

뉴턴알고리즘
------------

앞선 알고리즘에 미분가능이라는 조건이 더 붙는다.
*x*<sup>\*</sup>는 해 이기 때문에 0이라는 방정식을 만족한다.

$g(X) = x-(f(x)/f^\`(xn))$

마찬가지로 기울기가 0인 지점을 찾아줄 수 있다. 고정점 방법의 특별한 케이스로 이용되고 있다.
`미분가능한 이라는 조건만 있다면 고정점방법보다 수렴속도가 가장빠른 뉴턴방법이 좋다.`
초기값이 해 근처에야 수렴속도가 빠르다. 또한, 멀리있으면 무한루프에 빠져 수렴이 되지 않을 수도 있다. 해에 대한 정보를 조금 더 알 수 있으면 좋을 것이다.

어떻게 보면 고정점 방법의 특별한 케이스이다.
뉴턴알고리즘은 기울기를 이용한 방법이기 때문에, `미분 가능한 연속인 비선형방정식`에 대해서만 사용가능하다. ~~고정점알고리즘은 연속이던 미분가능하던 관심없다.~~

### Example)

``` r
# Newton

x1 <- 10
n <- 1

while(T){
    x0 <- x1
    fx <- x0^3-7*x0^2-7*x0-8
    dfx <- 3*x0^2-14*x0-7
    x1 <- x0-fx/dfx
    change <- abs((x1-x0)/x0)
    cat(n, x1, change, '\n')
    
    if( change < 1e-6 ) break;
    n <- n+1
}
```

    ## 1 8.54902 0.145098 
    ## 2 8.058929 0.05732706 
    ## 3 8.000792 0.007213989 
    ## 4 8 9.902824e-05 
    ## 5 8 1.827514e-08

선형이 아닌 방정식이다. 비선형 방정식이라고 볼 수 있다.
뉴턴알고리즘을 이용하려고 보면 미분가능한지, 연속인지 먼저 확인해야한다.
x&gt;0이므로 선형결합의 형태로 이루어져 있으므로 연속인 함수이다.

도함수를 구해보았다. 초기치가 필요하다.

뉴턴 알고리즘 단점으로 꼽자면 초기치를 찾고자하는 해로부터 멀리 두면 수렴하는 속도가 느리기도 하고, 또한 해를 구하지 못할 수도 있다.
비선형 방정식이다 보니까 곡선에서의 변곡점사이에 빠지게 되면 무한루프를 돌게되어 해를 찾을 수 없는 것 처럼 나온다. (해가 존재하긴 하지만)

해를 안다면 이런 알고리즘을 짤 필요 없다. 그래서 항상 초기치를 다양하게 두어 확인할 필요가 있다.

while문보다는 가능한 한 for문이 나을 것 같다. 초기치가 순환공식에 의해 해에 가가워지는데 무한루프에 빠질 수 있으므로 for문을 통해 반복횟수를 제한 하는 쪽이 더 나을 것이다.

``` r
library(Deriv)
Deriv("x0^3-7*x0^2-7*x0-8","x0")
```

    ## [1] "x0 * (3 * x0 - 14) - 7"

미분이 가능한 패키지를 사용하면 편리하다.

``` r
# Newton

x1 <- 10
n <- 1

for(i in 1:100){
    x0 <- x1
    
    fx <- x0^3-7*x0^2-7*x0-8
    dfx <- x0 * (3 * x0 - 14) - 7
    x1 <- x0 - fx/dfx
    
    change <- abs((x1-x0)/x0)
    cat(n, x1, change, '\n')
    
    if( change < 1e-6 ) break;
    n <- n+1
}
```

    ## 1 8.54902 0.145098 
    ## 2 8.058929 0.05732706 
    ## 3 8.000792 0.007213989 
    ## 4 8 9.902824e-05 
    ## 5 8 1.827514e-08

최대 반복횟수를 for문을 통해 제한하였다.

가우스 뉴턴 알고리즘 (ppt 참조)
-------------------------------

가우스가 뉴턴 알고리즘을 활용했다.
선형회귀모형에서 해를 구할 때, 보통 LSE를 사용함. 즉, 오차가 가능한 작은 방향으로 모형을 만드는 것도 좋은 방향인 것 같다.
관측하게 되는 표본들이 독립이기 때문에 오차항도 독립이라고 가정한다. 최소제곱추정량이 blue이기 때문에 mle대신 사용한다.

비선형인 경우도 순환공식을 여전히 사용할 것이다. 거기에다 테일러 급수도 사용할 것이다.
먼저, 급수전해를 한 모습이 첫번째 줄이다. 주어진 b의 값을 부여해서 순환공식을 활용(가장마지막 줄)

bm은 m번째 수열의 값(순환공식의 값)

beta1, beta2가 둘다 수렴해야 알고리즘은 수렴하였다라고 판단

종료 시 norm을 활용하였다. norm이 허용한계치보다 작다면 반복을 중단하고 *b*<sub>*m* + 1</sub>를 사용.
최소제곱 추정법을 이용한 과정이라고 볼 수 있다. 오차제곱을 최소로 만들어주는 하나의 추정치로 사용가능.
~~실습 생략(더 중요한 뉴턴 랩슨을 살펴보기)~~

뉴턴 랩슨 알고리즘
------------------

MLE를 이용한 방법이다.
가우스 뉴턴과 조금 다른 방법이다. 앞의 방법도 좋지만, 거의 대부분 활용도가 높은 것은 `Newton-Raphson`을 많이 쓴다.

-   L(theta | x) : 표본이 주어졌을 때, 모수에 대한 확률, theta의 함수
-   f(x| theta) : 모수가 주어졌을 때, 표본에 대한 확률

즉, 가능도함수는 모수의 관점에서 보게 된다.

-   가능도 함수를 왜 최대로 할까? 모수는 고정된 상수값, 하지만 우리는 모르고 있을 뿐이다.
    우리는 고정된 상수값을 알고싶어한다. 모집단의 특성을 나타내는 값이다. -&gt;모집단을 모르니 모수도 모른다.
    모수는 알고싶지만 모른다. 하지만, 표본같은 경우 언제든지 조사가능하다. 그래서 모집단의 일부분인 표본은 조사, 실험 가능하다.
    여기에서 보자면 x와 theta가 있을때, x는 구할 수 있지만, theta는 모른다.
    그래서 반대로 생각해보면 언제든지 관측가능한 표본을 통해 theta를 찾아내보자는 것이다.
    이 가능도함수에 대해 이야기 해야 한다.
    theta given x 이다. 가능도 함수를 이야기하자면, 확률값을 구하는 것이다. 확률값을 구할 때, 사건이 발생할 가능성에 대한 수치로 확률을 이야기 한다.
    theta의 값이 얼마일 확률이라고 말할 수 있다. 이 중에서 theta가 1,2일 확률이 0.1이고, 3일 확률이 0.8이면 가능성이 가장 높은 것을 선택할 것이다.
    이 theta가 특정할 값일 확률이 가장 높은 것을 선택하여 가능도 함수를 최대로 만들어주는 값을 선택한다.

### Example)

1.  *f*(*x*)=(1/4)*x*<sup>4</sup> − *x*<sup>2</sup>은 다항식이다.

``` r
newton <- function(f, df, tol = 1e-7, x0 = 1, N = 300){
  h <- 1e-7
  i <- 1
  x1 <- x0
  p <- numeric(N)
  while(i <= N){
    x1 <- (x0 - (f(x0) / df(x0)))
    p[i] <- x1
    i = i+1
    if(abs((x1 - x0)/x0) < tol) break
    x0 = x1
  }
  return(p[1:(i - 1)])
}
```

뉴턴랩슨방법을 이용해보자. 순환공식을 그대로 이용한다고 하면, 1계도함수, 2계도함수 등 2개가 필요하다.
f, df는 각각 1계,2계도함수를 말하며, tol은 오차한계를 표현하였다. x0는 초기값, N은 300으로 설정하였다.
f와 df는 값을 필수적으로 입력이 필요하다. 나머지는 값을 입력하지 않더라도 default로 입력된다.
N은 최대반복 횟수이다. (잘못하면 무한루프에 빠질 수 있으므로 최대 300번까지만 이 함수를 반복적으로 수행하고, 수렴하게 된다면 수렴했다고 보고 종료한다. 300번까지 했음에도 수렴하지 않으면 그냥 300번까지만 해보자)

``` r
Deriv("x^3+2","x")
```

    ## [1] "3 * x^2"

``` r
f <- function(x) x^3+2
df <- function(x) 3 * x^2


newton(f, df, x0 = 2)
```

    ##  [1]  1.1666667  0.2879819 -7.8465762 -5.2418788 -3.5188483 -2.3997392
    ##  [7] -1.7155920 -1.3702345 -1.2685637 -1.2599798 -1.2599211 -1.2599210

-1.26에 수렴하는 모습을 볼 수 있다.

1.  *f*(*x*|*λ*)=*λ**e**x**p*<sup>−*λ**x*</sup> 는 지수분포이다.

``` r
x<-c(.18740, .07779, 1.07893, .03122, .06175, 
    .46898, .44239, .04364, .94141, .21975)

Deriv("n*log(lambda)-lambda*sum(x)","lambda")  # derivative loglikelihood function with respect to lambda
```

    ## [1] "n/lambda - sum(x)"

``` r
Deriv("n/lambda - sum(x)","lambda")
```

    ## [1] "-(n/lambda^2)"

``` r
f <- function(lambda, x, n) n/lambda - sum(x)  #로그가능도함수를 람다에 대해 1번미분
df <- function(lambda, n) -n/(lambda^2)        #로그가능도함수를 람다에 대해 2번미분

newton <- function(f, df, tol = 1e-7, x0 = 1, x, N = 300){
  h <- 1e-7
  i <- 1
  x1 <- x0
  p <- numeric(N)
  while(i <= N){
    x1 <- (x0 - (f(x0, x, length(x)) / df(x0, length(x))))
    p[i] <- x1
    i = i+1
    if(abs((x1 - x0)/x0) < tol) break
    x0 = x1
  }
  return(p[1:(i - 1)])
}

newton(f, df, x0 = 1, x=x)
```

    ## [1] 1.644674 2.328208 2.730353 2.811812 2.814315 2.814317 2.814317

2계도함수분의 1계도함수의 비를 그냥 빼주게 되는 것이다. 왜 굳이 2계도함수로 하느냐? 우리가 원하는 해는 우도함수를 최대로 만들어주는 것이다. 최댓값은 모르기 때문에 0이되는 지점이 최대인것을 알고있으므로 $log^\`(\\theta)=0$식 자체가 비선형방정식을 푸는 것. 1계도함수를 *f*, 2계도함수를 $f^\`$이라고 보면 뉴턴 랩슨과 같은 방법이라고 생각된다. 관점의 차이이다.

람다를 모른다. 표본을 관측하고 람다의 값을 거꾸로 찾아내보자. 언제나 람다의 값을 찾고 f값을 계산할 수 있을 것이다.
지수분포는 x&gt;0이다. x는 첫번째 사건이 발생할 때 까지의 걸린 시간을 의미한다.
람다는 scale parameter(대략 퍼진정도)를 이야기 한다.

*L*(*λ*|*X* = *x*) 로그 가능도 함수를 이용해서 계산하였다.
x0가 람다0 에 대한 초기치를 부여한 것이다.

2.814317이라는 람다의 추정치를 구할 수 있었다.

``` r
f(2.814317,x,length(x))
```

    ## [1] -8.321735e-09

``` r
f(1/mean(x),x,length(x))  #mle : 1/xbar due to lambda
```

    ## [1] 0

지수분포가 (1/theta)exp^(1/theta)x 모양이었으면, mle가 xbar가 나왔을테지만 *λ*로 되어있어 mle는 역수형태가 된다. 위의 알고리즘을 통해 구한 해를 지수분포 함수 f에 대입했을 때, 거의 0이라는 값을 얻을 수 있어 해가 맞음을 확인할 수 있고, mle를 대입한 값은 당연히 0이 나오는 모습도 볼 수 있다.

#### while문을 활용한 algorithm 몇 가지 추가.

``` r
x1 <- 10   # first number to satisfy domain
n <- 1

while(T){
  x0 <- x1
  fx <- x0^3-7*x0^2-7*x0-8
  dfx <- 3*x0^2-14*x0-7
  x1 <- x0-fx/dfx      
  change <- abs((x1-x0)/x0)
  cat(n, x1, change, '\n')
  
  if( change < 1e-6 ) break;
  n <- n+1
  
  if(n>100) break;   
}

while(T){
  x0 <- x1
  fx <- x0^3-7*x0^2-7*x0-8
  dfx <- 3*x0^2-14*x0-7
  x1 <- x0-fx/dfx     
  change <- abs((x1-x0)/x0) 
  cat(n, x1, change, '\n')
  
  if( change < 1e-6 | n>100 ) break;
  n <- n+1
}


while(T){
  x0 <- x1
  fx <- x0^3-7*x0^2-7*x0-8
  dfx <- 3*x0^2-14*x0-7
  x1 <- x0-fx/dfx    
  change <- abs((x1-x0)/x0)
  cat(n, x1, change, '\n')
  
  if( change < 1e-6 ) break;
  n <- n+1
  
  if(n>100) break;  
}
```
